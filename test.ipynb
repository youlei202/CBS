{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1.],\n",
       "        [1., 1., 0.],\n",
       "        [0., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MaskedLinear(nn.Linear):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(MaskedLinear, self).__init__(in_features, out_features, bias)\n",
    "        self.register_buffer('weight_mask', torch.ones(out_features, in_features))\n",
    "\n",
    "    def forward(self, input):\n",
    "        masked_weight = self.weight * self.weight_mask\n",
    "        return nn.functional.linear(input, masked_weight, self.bias)\n",
    "\n",
    "# Create a simple model with a masked linear layer\n",
    "model = nn.Sequential(\n",
    "    MaskedLinear(3, 4),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(4, 2)\n",
    ")\n",
    "\n",
    "# Set a specific weight mask for the masked linear layer\n",
    "new_mask = torch.tensor([\n",
    "    [1, 0, 1],\n",
    "    [1, 1, 0],\n",
    "    [0, 1, 1],\n",
    "    [1, 1, 1]\n",
    "])\n",
    "model[0].weight_mask.copy_(new_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1.],\n",
       "        [1., 1., 0.],\n",
       "        [0., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].weight_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('hidden.weight', tensor([[-0.0608,  0.0539,  0.5331],\n",
      "        [-0.4810,  0.1233,  0.0555],\n",
      "        [-0.4860,  0.0546,  0.0107],\n",
      "        [-0.2816,  0.4855, -0.0054]])), ('hidden.bias', tensor([ 0.1430,  0.2492, -0.4270,  0.0581])), ('output.weight', tensor([[ 0.3120, -0.1003,  0.1688,  0.1702],\n",
      "        [-0.3985, -0.1890, -0.0265,  0.1303]])), ('output.bias', tensor([0.4874, 0.4113]))])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleFeedforward(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleFeedforward, self).__init__()\n",
    "        self.hidden = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "input_size = 3\n",
    "hidden_size = 4\n",
    "output_size = 2\n",
    "\n",
    "model = SimpleFeedforward(input_size, hidden_size, output_size)\n",
    "model_state_dict = model.state_dict()\n",
    "print(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0608,  0.0539,  0.5331],\n",
       "         [-0.4810,  0.1233,  0.0555],\n",
       "         [-0.4860,  0.0546,  0.0107],\n",
       "         [-0.2816,  0.4855, -0.0054]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.1430,  0.2492, -0.4270,  0.0581], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.3120, -0.1003,  0.1688,  0.1702],\n",
       "         [-0.3985, -0.1890, -0.0265,  0.1303]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.4874, 0.4113], requires_grad=True)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optim.SGD(model.parameters(), lr=1e-10).zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0608,  0.0539,  0.5331],\n",
       "         [-0.4810,  0.1233,  0.0555],\n",
       "         [-0.4860,  0.0546,  0.0107],\n",
       "         [-0.2816,  0.4855, -0.0054]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.1430,  0.2492, -0.4270,  0.0581], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.3120, -0.1003,  0.1688,  0.1702],\n",
       "         [-0.3985, -0.1890, -0.0265,  0.1303]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.4874, 0.4113], requires_grad=True)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0:\n",
      "Input tensor (in_tensor) shape: torch.Size([20, 10])\n",
      "Target tensor shape: torch.Size([20])\n",
      "\n",
      "Batch 1:\n",
      "Input tensor (in_tensor) shape: torch.Size([20, 10])\n",
      "Target tensor shape: torch.Size([20])\n",
      "\n",
      "Batch 2:\n",
      "Input tensor (in_tensor) shape: torch.Size([20, 10])\n",
      "Target tensor shape: torch.Size([20])\n",
      "\n",
      "Batch 3:\n",
      "Input tensor (in_tensor) shape: torch.Size([20, 10])\n",
      "Target tensor shape: torch.Size([20])\n",
      "\n",
      "Batch 4:\n",
      "Input tensor (in_tensor) shape: torch.Size([20, 10])\n",
      "Target tensor shape: torch.Size([20])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class RandomTensorDataset(Dataset):\n",
    "    def __init__(self, num_samples=100, input_size=10):\n",
    "        self.num_samples = num_samples\n",
    "        self.input_size = input_size\n",
    "        self.data = torch.randn(num_samples, input_size)\n",
    "        self.targets = torch.randint(0, 2, (num_samples,))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.targets[index]\n",
    "\n",
    "# Create a custom dataset with 100 samples, each with 10 features\n",
    "random_dataset = RandomTensorDataset(num_samples=100, input_size=10)\n",
    "\n",
    "# Create a DataLoader with a batch size of 20\n",
    "dummy_loader = DataLoader(random_dataset, batch_size=20, shuffle=True)\n",
    "\n",
    "# Loop through the DataLoader\n",
    "for batch_idx, (in_tensor, target) in enumerate(dummy_loader):\n",
    "    print(f\"Batch {batch_idx}:\")\n",
    "    print(f\"Input tensor (in_tensor) shape: {in_tensor.shape}\")\n",
    "    print(f\"Target tensor shape: {target.shape}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "def flatten_tensor_list(tensor_list):\n",
    "    return torch.cat([t.view(-1) for t in tensor_list])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 5)\n",
    "        self.fc2 = nn.Linear(5, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Create a simple model\n",
    "model = SimpleModel()\n",
    "\n",
    "# Create random input and target tensors\n",
    "in_tensor = torch.randn(1, 10)\n",
    "target = torch.tensor([1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(in_tensor)\n",
    "loss = criterion(output, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sample_fisher(loss, return_outer_product=True):\n",
    "    # The original function used self, but in our example,\n",
    "    # we removed self and replaced with the model and criterion we created earlier\n",
    "    _weight_only = False\n",
    "    _modules = [model.fc1, model.fc2]\n",
    "\n",
    "    ys = loss\n",
    "    params = []\n",
    "    m_idx = 0\n",
    "    for module in _modules:\n",
    "        m_idx += 1\n",
    "        for name, param in module.named_parameters():\n",
    "            if _weight_only and 'bias' in name:\n",
    "                continue\n",
    "            else:\n",
    "                params.append(param)\n",
    "\n",
    "    grads = torch.autograd.grad(ys, params)\n",
    "    grads = flatten_tensor_list(grads)\n",
    "    params = flatten_tensor_list(params)\n",
    "\n",
    "    gTw = params.T @ grads\n",
    "\n",
    "    if not return_outer_product:\n",
    "        return grads, None, gTw, params\n",
    "    else:\n",
    "        return torch.ger(grads, grads), grads, gTw, params\n",
    "\n",
    "result = compute_sample_fisher(loss,return_outer_product=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0898, -0.1266,  0.0653,  0.0692, -0.2971, -0.1322,  0.0081, -0.2103,\n",
       "        -0.2309, -0.2419,  0.0643, -0.0907,  0.0468,  0.0496, -0.2127, -0.0947,\n",
       "         0.0058, -0.1506, -0.1653, -0.1733,  0.0148, -0.0208,  0.0107,  0.0114,\n",
       "        -0.0488, -0.0217,  0.0013, -0.0346, -0.0379, -0.0398, -0.0074,  0.0105,\n",
       "        -0.0054, -0.0057,  0.0246,  0.0110, -0.0007,  0.0174,  0.0191,  0.0201,\n",
       "        -0.0000,  0.0000, -0.0000, -0.0000,  0.0000,  0.0000, -0.0000,  0.0000,\n",
       "         0.0000,  0.0000, -0.2876, -0.2060, -0.0473,  0.0239,  0.0000,  0.3242,\n",
       "         0.0914,  0.0735,  0.2146,  0.0000, -0.3242, -0.0914, -0.0735, -0.2146,\n",
       "        -0.0000,  0.4008, -0.4008])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 9, 9, 2, 2, 8, 9, 5, 8, 2])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.choice(10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradients tensor:\n",
      " tensor([[ 0.0021, -0.0111,  0.0155, -0.0009,  0.0021, -0.0066, -0.0117, -0.0051,\n",
      "          0.0031, -0.0150, -0.0392,  0.2069, -0.2899,  0.0173, -0.0387,  0.1233,\n",
      "          0.2182,  0.0956, -0.0586,  0.2817,  0.0225, -0.1186,  0.1662, -0.0099,\n",
      "          0.0222, -0.0707, -0.1251, -0.0548,  0.0336, -0.1616,  0.0164, -0.0865,\n",
      "          0.1212, -0.0072,  0.0162, -0.0516, -0.0912, -0.0400,  0.0245, -0.1178,\n",
      "         -0.0059,  0.0310, -0.0435,  0.0026, -0.0058,  0.0185,  0.0327,  0.0143,\n",
      "         -0.0088,  0.0422,  0.0014, -0.0255,  0.0146,  0.0107, -0.0038, -0.0780,\n",
      "         -0.1699, -0.2387,  0.1845, -0.0218,  0.0780,  0.1699,  0.2387, -0.1845,\n",
      "          0.0218,  0.0477, -0.0477],\n",
      "        [-0.0062,  0.0086,  0.0154,  0.0089, -0.0101, -0.0107,  0.0055,  0.0103,\n",
      "          0.0081, -0.0062,  0.1167, -0.1603, -0.2877, -0.1673,  0.1889,  0.2007,\n",
      "         -0.1033, -0.1936, -0.1521,  0.1161, -0.0669,  0.0919,  0.1650,  0.0960,\n",
      "         -0.1083, -0.1151,  0.0593,  0.1110,  0.0872, -0.0666, -0.0488,  0.0671,\n",
      "          0.1203,  0.0700, -0.0790, -0.0840,  0.0432,  0.0810,  0.0636, -0.0486,\n",
      "          0.0175, -0.0240, -0.0431, -0.0251,  0.0283,  0.0301, -0.0155, -0.0290,\n",
      "         -0.0228,  0.0174,  0.0015, -0.0283,  0.0162,  0.0118, -0.0042, -0.2888,\n",
      "         -0.0099, -0.1652, -0.1408,  0.1954,  0.2888,  0.0099,  0.1652,  0.1408,\n",
      "         -0.1954,  0.0529, -0.0529]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, SubsetRandomSampler\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 5)\n",
    "        self.fc2 = nn.Linear(5, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def flatten_tensor_list(tensors):\n",
    "    return torch.cat([t.view(-1) for t in tensors])\n",
    "\n",
    "# Create a small dataset with 4 samples\n",
    "in_tensor = torch.randn(4, 10)\n",
    "target = torch.tensor([1, 0, 1, 0])\n",
    "dataset = TensorDataset(in_tensor, target)\n",
    "\n",
    "def compute_sample_fisher(loss, return_outer_product=True):\n",
    "    _weight_only = False\n",
    "    _modules = [model.fc1, model.fc2]\n",
    "\n",
    "    ys = loss\n",
    "    params = []\n",
    "    m_idx = 0\n",
    "    for module in _modules:\n",
    "        m_idx += 1\n",
    "        for name, param in module.named_parameters():\n",
    "            if _weight_only and 'bias' in name:\n",
    "                continue\n",
    "            else:\n",
    "                params.append(param)\n",
    "\n",
    "    grads = torch.autograd.grad(ys, params)\n",
    "    grads = flatten_tensor_list(grads)\n",
    "    params = flatten_tensor_list(params)\n",
    "\n",
    "    gTw = params.T @ grads\n",
    "\n",
    "    if not return_outer_product:\n",
    "        return grads, None, gTw, params\n",
    "    else:\n",
    "        return torch.ger(grads, grads), grads, gTw, params\n",
    "\n",
    "def _compute_wgH(model, dummy_loader, device, args, _fisher_mini_bsz):\n",
    "    model = model.to(device)\n",
    "\n",
    "    goal = args.fisher_subsample_size\n",
    "\n",
    "    assert len(subset_indices) == goal * args.fisher_mini_bsz\n",
    "\n",
    "    Gs = []\n",
    "\n",
    "    if args.disable_log_soft:\n",
    "        criterion = torch.nn.functional.cross_entropy\n",
    "    else:\n",
    "        criterion = nn.functional.nll_loss\n",
    "\n",
    "    num_batches = 0\n",
    "    num_samples = 0\n",
    "\n",
    "    for in_tensor, target in dummy_loader:\n",
    "        in_tensor, target = in_tensor.to(device), target.to(device)\n",
    "        output = model(in_tensor)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        g, _, _, _ = compute_sample_fisher(loss, return_outer_product=False)\n",
    "        Gs.append(g[None, :].detach().cpu())\n",
    "\n",
    "        num_batches += 1\n",
    "        num_samples += _fisher_mini_bsz\n",
    "        if num_samples == goal * args.fisher_mini_bsz:\n",
    "            break\n",
    "\n",
    "    grads = torch.cat(Gs, 0)\n",
    "    return grads\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleModel()\n",
    "\n",
    "subset_indices = list(range(len(dataset)))\n",
    "args = lambda: None\n",
    "args.fisher_subsample_size = 2\n",
    "args.fisher_mini_bsz = len(dataset) // args.fisher_subsample_size\n",
    "args.disable_log_soft = True\n",
    "\n",
    "dummy_loader = DataLoader(dataset, batch_size=args.fisher_mini_bsz, sampler=SubsetRandomSampler(subset_indices))\n",
    "\n",
    "grads = _compute_wgH(model, dummy_loader, device, args, args.fisher_mini_bsz)\n",
    "print(\"Gradients tensor:\\n\", grads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([67, 67])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(grads.T @ grads).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
